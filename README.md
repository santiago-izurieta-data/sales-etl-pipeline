# Sales ETL Pipeline

![Python](https://img.shields.io/badge/python-v3.9+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸ“‹ DescripciÃ³n

Pipeline ETL automatizado que procesa datos de ventas desde archivos CSV, realiza transformaciones y validaciones, y carga los resultados en una base de datos PostgreSQL para anÃ¡lisis posterior.

## ğŸ¯ Objetivos

- Extraer datos de mÃºltiples fuentes (CSV, APIs)
- Limpiar y transformar datos inconsistentes
- Validar calidad de datos
- Cargar datos en base de datos relacional
- Generar reportes automÃ¡ticos

## ğŸ› ï¸ Stack TecnolÃ³gico

- **Python 3.9+**
- **Pandas** - ManipulaciÃ³n de datos
- **SQLAlchemy** - ORM para base de datos
- **PostgreSQL** - Base de datos
- **pytest** - Testing
- **logging** - Monitoreo

## ğŸ“ Estructura del Proyecto

sales-etl-pipeline/ â”œâ”€â”€ data/ # Datos raw y procesados â”œâ”€â”€ src/ # CÃ³digo fuente â”œâ”€â”€ notebooks/ # AnÃ¡lisis exploratorio â”œâ”€â”€ tests/ # Tests unitarios â””â”€â”€ config/ # Archivos de configuraciÃ³n

## ğŸš€ InstalaciÃ³n

### Prerrequisitos
- Python 3.9 o superior
- PostgreSQL instalado
- pip o conda

### Pasos

1. Clonar el repositorio:
```bash
git clone https://github.com/tu-usuario/sales-etl-pipeline.git
cd sales-etl-pipeline
2.	Crear entorno virtual:
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
3.	Instalar dependencias:
pip install -r requirements.txt
4.	Configurar variables de entorno:
cp .env.example .env
# Editar .env con tus credenciales
ğŸ’» Uso
Ejecutar pipeline completo:
python src/pipeline.py
Ejecutar etapas individuales:
python src/extract.py
python src/transform.py
python src/load.py
ğŸ§ª Testing
pytest tests/
ğŸ“Š Resultados
â€¢	Procesamiento de +10,000 registros/minuto
â€¢	ReducciÃ³n de 30% en datos duplicados
â€¢	AutomatizaciÃ³n completa del proceso diario
ğŸ”„ Pipeline Flow
CSV Files â†’ Extract â†’ Validate â†’ Transform â†’ Load â†’ PostgreSQL
                                                   â†“
                                              Data Quality
                                                 Report
ğŸ“ˆ PrÃ³ximas Mejoras
â€¢	[ ] IntegraciÃ³n con Airflow para scheduling
â€¢	[ ] DockerizaciÃ³n del proyecto
â€¢	[ ] Dashboard de monitoreo
â€¢	[ ] IntegraciÃ³n con AWS S3
ğŸ“ Licencia
Este proyecto estÃ¡ bajo la Licencia MIT - ver LICENSE para detalles.
ğŸ‘¤ Autor
Tu Nombre
â€¢	LinkedIn: tu-perfil
â€¢	Portfolio: tu-portfolio.lovable.app
â€¢	Email: tu.email@example.com
ğŸ™ Agradecimientos
â€¢	Comunidad de Python
â€¢	DocumentaciÃ³n de Pandas
